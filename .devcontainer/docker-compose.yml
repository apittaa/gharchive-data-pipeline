services:
  app:
    # Builds the `app` service using the specified Dockerfile located at `.devcontainer/Dockerfile`
    build: 
      context: ..  # The build context is the parent directory
      dockerfile: .devcontainer/Dockerfile  # Path to the Dockerfile
    container_name: gharchive  # The container will be named 'gharchive'
    
    # Mounts the project directory into the container for live code syncing
    volumes:
      - ..:/workspace:cached  # Mount the parent directory to `/workspace` in the container
      - dagster-home:/workspace/gharchive_dagster/dagster_home  # Mounts a persistent volume for Dagster's home directory
    
    # Sets environment variables for the container
    environment:
      DAGSTER_HOME: /workspace/gharchive_dagster/dagster_home  # Specifies the directory where Dagster will store persistent data
    
    # Keeps the container running by executing a long-running dummy command
    command: /bin/sh -c "while sleep 1000; do :; done"

  trino:
    hostname: trino  # The hostname for the Trino service
    image: trinodb/trino  # The image used to run Trino
    ports:
      - '8080:8080'  # Maps port 8080 for the Trino service
    volumes:
       - ../trino/catalog:/etc/trino/catalog:ro

# HMS backend database
  metastore_db:
    image: postgres:11
    hostname: metastore_db
    container_name: metastore_db
    environment:
      POSTGRES_USER: hive
      POSTGRES_PASSWORD: hive
      POSTGRES_DB: metastore

  # Hive metastore service (HMS)
  hive-metastore:
    container_name: hive-metastore
    hostname: hive-metastore
    image: 'starburstdata/hive:3.1.2-e.15'
    ports:
      - '9083:9083' # Metastore Thrift
    environment:
      HIVE_METASTORE_DRIVER: org.postgresql.Driver
      HIVE_METASTORE_JDBC_URL: jdbc:postgresql://metastore_db:5432/metastore
      HIVE_METASTORE_USER: hive
      HIVE_METASTORE_PASSWORD: hive
      HIVE_METASTORE_WAREHOUSE_DIR: s3://"$${GOLD_BUCKET}"/
      S3_ENDPOINT: http://s3service:9000
      S3_ACCESS_KEY: "$${ACCESS_KEY}"
      S3_SECRET_KEY: "$${SECRET_KEY}"
      S3_PATH_STYLE_ACCESS: "true"
      REGION: ""
      GOOGLE_CLOUD_KEY_FILE_PATH: ""
      AZURE_ADL_CLIENT_ID: ""
      AZURE_ADL_CREDENTIAL: ""
      AZURE_ADL_REFRESH_URL: ""
      AZURE_ABFS_STORAGE_ACCOUNT: ""
      AZURE_ABFS_ACCESS_KEY: ""
      AZURE_WASB_STORAGE_ACCOUNT: ""
      AZURE_ABFS_OAUTH: ""
      AZURE_ABFS_OAUTH_TOKEN_PROVIDER: ""
      AZURE_ABFS_OAUTH_CLIENT_ID: ""
      AZURE_ABFS_OAUTH_SECRET: ""
      AZURE_ABFS_OAUTH_ENDPOINT: ""
      AZURE_WASB_ACCESS_KEY: ""
    depends_on:
      - metastore_db

    # Loads environment variables from an external file
    env_file: ../envs/minio.env  # Loads environment variables from a file

  s3service:
    # Pulls the Minio image to create an object storage service
    image: quay.io/minio/minio  # The image used to run Minio
    container_name: minio  # The container will be named 'minio'
    
    # Maps the container's ports to the host machine, enabling access to Minio's services
    ports:
      - '9000:9000'  # Maps port 9000 for the Minio service
      - '9001:9001'  # Maps port 9001 for Minio's console
    
    # Loads environment variables from an external file
    env_file: ../envs/minio.env  # Loads environment variables from a file
    
    # Mounts a volume to persist Minio data
    volumes:
      - minio-data:/workspace/data/minio  # Mounts a persistent volume to store Minio data
    
    # Configures the entrypoint script to start Minio with the specified environment variables
    command: server data --console-address ":9001"

  initialize-s3service:
    # Uses Minio's client (`mc`) to initialize buckets and users in the Minio service
    image: quay.io/minio/mc  # The image used to run Minio Client (mc)
    container_name: miniomc  # The container will be named 'miniomc'
    
    # Specifies that this service depends on the Minio service, ensuring Minio starts first
    depends_on:
      - s3service  # Wait for the s3service (Minio) to be available before running
    
    # The entrypoint script that sets up Minio with buckets and user accounts
    entrypoint: >
      /bin/sh -c '
      /usr/bin/mc alias set s3service http://s3service:9000 "$${MINIO_ROOT_USER}" "$${MINIO_ROOT_PASSWORD}";
      /usr/bin/mc mb s3service/"$${BRONZE_BUCKET}";
      /usr/bin/mc mb s3service/"$${SILVER_BUCKET}";
      /usr/bin/mc mb s3service/"$${GOLD_BUCKET}";
      /usr/bin/mc admin user add s3service "$${ACCESS_KEY}" "$${SECRET_KEY}";
      /usr/bin/mc admin policy attach s3service readwrite --user "$${ACCESS_KEY}";
      exit 0;
      '
    
    # Loads environment variables from an external file
    env_file: ../envs/minio.env  # Loads environment variables from a file

# Declare the named volumes used by the services
volumes:
  minio-data: {}  # Persistent storage for Minio data, managed by Docker
  dagster-home: {}  # Persistent storage for Dagster's home directory, managed by Docker

networks:
  trino-networks:
    driver: bridge  # Specifies the network driver for the Trino service
